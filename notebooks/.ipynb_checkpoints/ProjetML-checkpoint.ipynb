{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "043f2326-8fdf-4f3f-9630-5955d48ae4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4c44852e-d526-4437-82e7-6c5f0c1169b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i just feel really helpless and heavy hearted</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i gave up my internship with the dmrg and am f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i dont know i feel so lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>i feel that shakespeare is a talented man of h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>ill be attending college classes and ill have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>i am a girl and i am utterly dependent on my i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>ive been feeling less inhibited</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>ive got to say today im feeling especially gor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  label\n",
       "0              0      i just feel really helpless and heavy hearted      4\n",
       "1              1  ive enjoyed being able to slouch about relax a...      0\n",
       "2              2  i gave up my internship with the dmrg and am f...      4\n",
       "3              3                         i dont know i feel so lost      0\n",
       "4              4  i am a kindergarten teacher and i am thoroughl...      4\n",
       "...          ...                                                ...    ...\n",
       "9995        9995  i feel that shakespeare is a talented man of h...      1\n",
       "9996        9996  ill be attending college classes and ill have ...      1\n",
       "9997        9997  i am a girl and i am utterly dependent on my i...      0\n",
       "9998        9998                    ive been feeling less inhibited      4\n",
       "9999        9999  ive got to say today im feeling especially gor...      1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('text.csv')\n",
    "df2=df.copy()\n",
    "df2=df2.head(10000)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "470f667d-dec7-4263-a908-30dbfdb0b77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[i, just, feel, really, helpless, and, heavy, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[ive, enjoyed, being, able, to, slouch, about,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[i, gave, up, my, internship, with, the, dmrg,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[i, dont, know, i, feel, so, lost]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[i, am, a, kindergarten, teacher, and, i, am, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>[i, feel, that, shakespeare, is, a, talented, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>[ill, be, attending, college, classes, and, il...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>[i, am, a, girl, and, i, am, utterly, dependen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>[ive, been, feeling, less, inhibited]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>[ive, got, to, say, today, im, feeling, especi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  label\n",
       "0              0  [i, just, feel, really, helpless, and, heavy, ...      4\n",
       "1              1  [ive, enjoyed, being, able, to, slouch, about,...      0\n",
       "2              2  [i, gave, up, my, internship, with, the, dmrg,...      4\n",
       "3              3                 [i, dont, know, i, feel, so, lost]      0\n",
       "4              4  [i, am, a, kindergarten, teacher, and, i, am, ...      4\n",
       "...          ...                                                ...    ...\n",
       "9995        9995  [i, feel, that, shakespeare, is, a, talented, ...      1\n",
       "9996        9996  [ill, be, attending, college, classes, and, il...      1\n",
       "9997        9997  [i, am, a, girl, and, i, am, utterly, dependen...      0\n",
       "9998        9998              [ive, been, feeling, less, inhibited]      4\n",
       "9999        9999  [ive, got, to, say, today, im, feeling, especi...      1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['text'] = df2['text'].str.split(' ',)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "004fea4b-bfc0-481b-98d0-ed23e17f7013",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cypri\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  aaron  aatp  aback  abandon  abandoned  abandoning  abandonment  abc  \\\n",
      "0  0      0     0      0        0          0           0            0    0   \n",
      "1  2      0     0      0        0          0           0            0    0   \n",
      "2  0      0     0      0        0          0           0            0    0   \n",
      "3  0      0     0      0        0          0           0            0    0   \n",
      "4  1      0     0      0        0          0           0            0    0   \n",
      "\n",
      "   abdominal  ...  zingers  ziva  zombie  zone  zoom  zooming  zouk  zumba  \\\n",
      "0          0  ...        0     0       0     0     0        0     0      0   \n",
      "1          0  ...        0     0       0     0     0        0     0      0   \n",
      "2          0  ...        0     0       0     0     0        0     0      0   \n",
      "3          0  ...        0     0       0     0     0        0     0      0   \n",
      "4          0  ...        0     0       0     0     0        0     0      0   \n",
      "\n",
      "   zurich  zz  \n",
      "0       0   0  \n",
      "1       0   0  \n",
      "2       0   0  \n",
      "3       0   0  \n",
      "4       0   0  \n",
      "\n",
      "[5 rows x 11812 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(lowercase=False, tokenizer=lambda x: x, preprocessor=lambda x: x)\n",
    "\n",
    "X = vectorizer.fit_transform(df2['text'])\n",
    "\n",
    "df_encoded = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(df_encoded.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "87a10145-0b42-460c-a668-83ee01f5d695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      a  aaron  aatp  aback  abandon  abandoned  abandoning  abandonment  abc  \\\n",
      "0     0      0     0      0        0          0           0            0    0   \n",
      "1     2      0     0      0        0          0           0            0    0   \n",
      "2     0      0     0      0        0          0           0            0    0   \n",
      "3     0      0     0      0        0          0           0            0    0   \n",
      "4     1      0     0      0        0          0           0            0    0   \n",
      "...  ..    ...   ...    ...      ...        ...         ...          ...  ...   \n",
      "9995  3      0     0      0        0          0           0            0    0   \n",
      "9996  1      0     0      0        0          0           0            0    0   \n",
      "9997  1      0     0      0        0          0           0            0    0   \n",
      "9998  0      0     0      0        0          0           0            0    0   \n",
      "9999  0      0     0      0        0          0           0            0    0   \n",
      "\n",
      "      abdominal  ...  ziva  zombie  zone  zoom  zooming  zouk  zumba  zurich  \\\n",
      "0             0  ...     0       0     0     0        0     0      0       0   \n",
      "1             0  ...     0       0     0     0        0     0      0       0   \n",
      "2             0  ...     0       0     0     0        0     0      0       0   \n",
      "3             0  ...     0       0     0     0        0     0      0       0   \n",
      "4             0  ...     0       0     0     0        0     0      0       0   \n",
      "...         ...  ...   ...     ...   ...   ...      ...   ...    ...     ...   \n",
      "9995          0  ...     0       0     0     0        0     0      0       0   \n",
      "9996          0  ...     0       0     0     0        0     0      0       0   \n",
      "9997          0  ...     0       0     0     0        0     0      0       0   \n",
      "9998          0  ...     0       0     0     0        0     0      0       0   \n",
      "9999          0  ...     0       0     0     0        0     0      0       0   \n",
      "\n",
      "      zz  label  \n",
      "0      0      4  \n",
      "1      0      0  \n",
      "2      0      4  \n",
      "3      0      0  \n",
      "4      0      4  \n",
      "...   ..    ...  \n",
      "9995   0      1  \n",
      "9996   0      1  \n",
      "9997   0      0  \n",
      "9998   0      4  \n",
      "9999   0      1  \n",
      "\n",
      "[10000 rows x 11813 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot index with multidimensional key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[270], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df_concatenated \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_encoded, df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_concatenated)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_concatenated[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[df_concatenated[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot index with multidimensional key"
     ]
    }
   ],
   "source": [
    "df_concatenated = pd.concat([df_encoded, df2['label']], axis=1)\n",
    "print(df_concatenated)\n",
    "print(df_concatenated['label'].loc[df_concatenated['label']>=5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4adde349-3609-4d85-8ef1-3d0b9d8bd592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "288/288 [==============================] - 9s 28ms/step - loss: 1.1007 - accuracy: 0.6098\n",
      "Epoch 2/5\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.2127 - accuracy: 0.9347\n",
      "Epoch 3/5\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.0558 - accuracy: 0.9840\n",
      "Epoch 4/5\n",
      "288/288 [==============================] - 8s 28ms/step - loss: 0.0248 - accuracy: 0.9936\n",
      "Epoch 5/5\n",
      "288/288 [==============================] - 8s 29ms/step - loss: 0.0138 - accuracy: 0.9963\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.8512\n",
      "Test accuracy: 0.8512499928474426\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#(train_data, train_labels), (test_data, test_labels) = df_concatenated.load_data()\n",
    "#print(train_data)\n",
    "#print(test_labels)\n",
    "\n",
    "#train_labels_one_hot = to_categorical(train_labels, num_classes=6)\n",
    "#test_labels_one_hot = to_categorical(test_labels, num_classes=6)\n",
    "\n",
    "#train_data = df_encoded.head(800)\n",
    "#train_labels = df2['label'].head(800)\n",
    "#test_data = df_encoded[800:999]\n",
    "#test_labels = df2['label'][800:999]\n",
    "\n",
    "#train_data_np = train_data.to_numpy().astype('float32')\n",
    "#train_labels_np = to_categorical(train_labels.to_numpy())\n",
    "#train_labels_np = tf.keras.utils.to_categorical(train_labels_np, num_classes=6)\n",
    "#test_data_np = test_data.to_numpy().astype('float32')\n",
    "#test_labels_np = to_categorical(test_labels.to_numpy())\n",
    "#test_labels_np = tf.keras.utils.to_categorical(test_labels_np, num_classes=6)\n",
    "\n",
    "X_test = df_concatenated.head(800).iloc[:, :-1].values\n",
    "y_test = df_concatenated.head(800).iloc[:, -1].values\n",
    "X_train = df_concatenated[800:].iloc[:, :-1].values\n",
    "y_train = df_concatenated[800:].iloc[:, -1].values\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "#print(X_test[-1].shape)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'), \n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_one_hot, epochs=5, batch_size=32)\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot, batch_size=32)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "adfed180-2e77-4e98-b6d1-9fab91e224b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modele_trained.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0d6c01b0-9841-44c4-b054-d262f987f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "modele_charge = load_model('modele_trained.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f73459bc-92f3-48f7-86b2-3becffb7d76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3=df.copy().head(1000)\n",
    "\n",
    "#def transf_en_hot(texte):\n",
    "    #texte_sep=[texte.split(' ',)]\n",
    "    #print(texte_sep)\n",
    "    #texte_df = pd.DataFrame([texte_sep])\n",
    "    #print(texte_df)\n",
    "    #df3=df.copy().head(1000)\n",
    "    #df3['text'] = df3['text'].str.split(' ',)\n",
    "    #df_total=pd.concat([df3['text'], texte_df], axis=0)\n",
    "    #print(df_total)\n",
    "    #df_total_vect = vectorizer.fit_transform(df_total[0])\n",
    "    #print(df_total_vect)\n",
    "    #df_total_encoded = pd.DataFrame(df_total_vect.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    #print(df_total_encoded)\n",
    "    #return(df_total_encoded.iloc[-1].values)\n",
    "def transf(texte,vectorizer):\n",
    "    texte_preprocessed = [texte]  # Appliquez votre logique de tokenisation/prétraitement si nécessaire\n",
    "    texte_vect = vectorizer.transform(texte_preprocessed)\n",
    "    return texte_vect.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3bd92a59-ac91-4556-866b-81c8cb6284f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[4.8358059e-03 9.9066484e-01 4.3781416e-05 4.4221664e-03 1.2113934e-05\n",
      "  2.1427488e-05]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "prediction = modele_charge.predict(transf('i feel sad bro',vectorizer))\n",
    "print(prediction)\n",
    "classe_predite = np.argmax(prediction, axis=1)\n",
    "print(classe_predite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b635fd5-5e61-44c1-8613-4b706e1d4cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf0c69-9418-4bbb-8579-d56f6a5be854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
